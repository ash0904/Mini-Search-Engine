{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import xml.etree.ElementTree as ET\n",
    "import re                                                           \n",
    "from collections import defaultdict\n",
    "# from nltk.stem import PorterStemmer\n",
    "from Stemmer import Stemmer\n",
    "import time\n",
    "\n",
    "def my_tokenizer(text):\n",
    "    words = re.split(r'(\\b[^\\s]+\\b)((?<=\\.\\w).)?', text)\n",
    "    tok = [i for i in words if i!=None and i != \" \" and i != \"\"]\n",
    "    tok = [ word.lower() for word in tok if re.match('^[a-zA-Z0-9\\'-.]+$',word) and not re.match('^[0-9_]+$',word)]\n",
    "    return tok\n",
    "\n",
    "\n",
    "ps = Stemmer(\"english\")\n",
    "\n",
    "# ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def strip_tag_name(t):\n",
    "    t = elem.tag\n",
    "    idx = k = t.rfind(\"}\")\n",
    "    if idx != -1:\n",
    "        t = t[idx + 1:]\n",
    "    return t\n",
    "\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "def stopWords(listOfWords):                                         #Stop Words Removal\n",
    "    temp=[key for key in listOfWords if key not in stop_words]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findInfoBoxTextCategory(data):                                        #find InfoBox, Text and Category\n",
    "    info=[]\n",
    "    bodyText=[]\n",
    "    category=[]\n",
    "    links=[]\n",
    "    flagtext=1\n",
    "    lines = data.split('\\n')\n",
    "    for i in xrange(len(lines)):\n",
    "        if '{{infobox' in lines[i]:\n",
    "            flag=0\n",
    "            temp=lines[i].split('{{infobox')[1:]\n",
    "            info.extend(temp)\n",
    "            while True:\n",
    "                if '{{' in lines[i]:\n",
    "                    count=lines[i].count('{{')\n",
    "                    flag+=count\n",
    "                if '}}' in lines[i]:\n",
    "                    count=lines[i].count('}}')\n",
    "                    flag-=count\n",
    "                if flag<=0:\n",
    "                    break\n",
    "                i+=1\n",
    "                info.append(lines[i])\n",
    "\n",
    "        elif flagtext:\n",
    "            if '[[category' in lines[i] or '==external links==' in lines[i]:\n",
    "                flagtext=0\n",
    "            bodyText.append(lines[i])\n",
    "            \n",
    "    else:\n",
    "        if \"[[category\" in lines[i]:\n",
    "            line = data.split(\"[[category:\")\n",
    "            if len(line)>1:\n",
    "                category.extend(line[1:-1])\n",
    "                temp=line[-1].split(']]')\n",
    "                category.append(temp[0])\n",
    "\n",
    "    category = my_tokenizer(' '.join(category))\n",
    "    category = stopWords(category)\n",
    "    category = map(ps.stemWord, category)\n",
    "\n",
    "    info = my_tokenizer(' '.join(info))\n",
    "    info = stopWords(info)\n",
    "    info = map(ps.stemWord,info)\n",
    "\n",
    "    bodyText = my_tokenizer(' '.join(bodyText))\n",
    "    bodyText = stopWords(bodyText)\n",
    "    bodyText = map(ps.stemWord, bodyText)\n",
    "\n",
    "    infobox = defaultdict(int)\n",
    "    for key in info:\n",
    "        infobox[key] += 1\n",
    "\n",
    "    bodyTxt = defaultdict(int)\n",
    "    for key in bodyText:\n",
    "        bodyTxt[key] += 1\n",
    "\n",
    "    categ = defaultdict(int)\n",
    "    for key in category:\n",
    "        categ[key] += 1\n",
    "  \n",
    "    return infobox, bodyTxt, categ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(title, text):\n",
    "    twords = my_tokenizer(title)\n",
    "    twords = stopWords(twords)\n",
    "    twords = map(ps.stemWord, twords)\n",
    "    \n",
    "    ttokens = defaultdict(int)\n",
    "    for key in twords:\n",
    "        ttokens[key]+=1\n",
    "    info, bodyText, category = findInfoBoxTextCategory(text)\n",
    "    return ttokens, bodyText, info, category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "Elapsed time: 0:01:30.34\n"
     ]
    }
   ],
   "source": [
    "dumpPath = 'wiki-search-small.xml'\n",
    "# dumpPath = 'test.xml'\n",
    "\n",
    "start_time = time.time()\n",
    "totalCount = 0\n",
    "temp = -1\n",
    "inver = defaultdict(str)\n",
    "for event, elem in ET.iterparse(dumpPath, events=('start', 'end')):\n",
    "    tname = strip_tag_name(elem.tag)\n",
    "    if event == 'start':\n",
    "        if tname == 'page':\n",
    "            title = ''\n",
    "            did = -1\n",
    "            redirect = ''\n",
    "            inrevision = False\n",
    "            ns = 0\n",
    "            text = ''\n",
    "        elif tname == 'revision':\n",
    "            # Do not pick up on revision id's\n",
    "            inrevision = True\n",
    "    else:\n",
    "        if tname == 'title':\n",
    "            title = elem.text\n",
    "        elif tname == 'id' and not inrevision:\n",
    "            did = int(elem.text)\n",
    "        elif tname == 'redirect':\n",
    "            redirect = elem.attrib['title']\n",
    "        elif tname == 'ns':\n",
    "            ns = int(elem.text)\n",
    "        elif tname == 'text':\n",
    "            text = elem.text\n",
    "        elif tname == 'page':\n",
    "            if redirect == \"\":\n",
    "                redirect = title\n",
    "            ttoken, body, tinfo, tcat = create_index(redirect,text)\n",
    "            for keys in set(ttoken.keys() + body.keys() + tinfo.keys()):\n",
    "                inver[keys] += \"|\" + str(did)\n",
    "                if keys in ttoken:\n",
    "                    inver[keys] += \"t\" + str(ttoken[keys])\n",
    "                if keys in body:\n",
    "                    inver[keys] += \"b\" + str(body[keys])\n",
    "                if keys in tinfo:\n",
    "                    inver[keys] += \"i\" + str(tinfo[keys])\n",
    "                if keys in tcat:\n",
    "                    inver[keys] += \"c\" + str(tcat[keys])\n",
    "            totalCount += 1\n",
    "        elem.clear()\n",
    "#         if (totalCount%100 == 0 and totalCount != temp):\n",
    "#             temp = totalCount\n",
    "#             print totalCount\n",
    "# for keys in inver:\n",
    "#     print keys,inver[keys]\n",
    "with open('invertedIndex.txt', 'w') as fil:\n",
    "    for key in inver:\n",
    "        fil.write(key.encode('ascii', 'ignore').decode('ascii') + inver[key] + \"\\n\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed time: {}\".format(hms_string(elapsed_time)))\n",
    "# print totalCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
